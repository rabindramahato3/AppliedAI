{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Assigntment_5_Performance_metrics_Instructions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KbsWXuDaQvnq",
        "wX1ewYjTY3bI",
        "kMGeLCzfRe1Z",
        "nf6YPh8MRn6x",
        "FV47GZ31Vu9t",
        "r-r9RTqLY_j6",
        "_EhPdi4fZatV",
        "V5KZem1BQvn2",
        "C-3sPkZQHKYB",
        "rlCe6dDCHKYC",
        "DAD4FNLhHKYC",
        "mE6eTHqOHKYD",
        "Na8fy2G6HKYD",
        "GiPGonTzQvoB",
        "F5AlGM1yBBxK",
        "sD4CcgjXQvoL",
        "kfg4BE_FReXV",
        "FkrSMTW0Wk_6",
        "AnNRhsf1cq3o"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabindramahato3/AppliedAI/blob/main/5_Assigntment_5_Performance_metrics_Instructions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV"
      },
      "source": [
        "# Compute performance metrics for the given Y and Y_score without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHb6NE7Qvnc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# other than these two you should not import any other packages"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbsWXuDaQvnq"
      },
      "source": [
        "\n",
        "## A. Compute performance metrics for the given data '5_a.csv'\n",
        " <pre>  <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use<br> numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> <br>Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
        "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX1ewYjTY3bI"
      },
      "source": [
        "### Read the data from 5_a.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFLW7oBQvnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7353e3e-8cf7-4d4d-8b7d-eeacc5f26e46"
      },
      "source": [
        "df_a=pd.read_csv('5_a.csv')\n",
        "print(df_a.head(10))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     y     proba\n",
            "0  1.0  0.637387\n",
            "1  1.0  0.635165\n",
            "2  1.0  0.766586\n",
            "3  1.0  0.724564\n",
            "4  1.0  0.889199\n",
            "5  1.0  0.601600\n",
            "6  1.0  0.666323\n",
            "7  1.0  0.567012\n",
            "8  1.0  0.650230\n",
            "9  1.0  0.829346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg8uUJvGAfCM"
      },
      "source": [
        "# write your code here for task A"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMGeLCzfRe1Z"
      },
      "source": [
        "### Deriving class labels from the given score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdXcS1VZZ8M7",
        "outputId": "b9936045-5b16-48c0-814a-d5d589538bb4"
      },
      "source": [
        "\n",
        "\n",
        "df_a['y_pred'] = [0 if prob < 0.5 else 1 for prob in list(df_a.proba) ]\n",
        "print(df_a.head(10))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     y     proba  y_pred\n",
            "0  1.0  0.637387       1\n",
            "1  1.0  0.635165       1\n",
            "2  1.0  0.766586       1\n",
            "3  1.0  0.724564       1\n",
            "4  1.0  0.889199       1\n",
            "5  1.0  0.601600       1\n",
            "6  1.0  0.666323       1\n",
            "7  1.0  0.567012       1\n",
            "8  1.0  0.650230       1\n",
            "9  1.0  0.829346       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf6YPh8MRn6x"
      },
      "source": [
        "### 1. Computing Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQjGmnlTZ2ZF"
      },
      "source": [
        "def ConfusionMatrix(y, y_predicted):\n",
        "  '''\n",
        "    given y-class scores and y-predicted class scores \n",
        "    create a confusion matrix\n",
        "  '''\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for y, y_pred in zip(y, y_predicted):\n",
        "    if y == 0 and y_pred == 0:\n",
        "      tn = tn + 1\n",
        "    elif y == 0 and y_pred == 1:\n",
        "      fp = fp + 1\n",
        "    elif y == 1 and y_pred == 0:\n",
        "      fn = fn + 1\n",
        "    elif y == 1 and y_pred == 1:\n",
        "      tp = tp + 1\n",
        "  \n",
        "  matrix = np.matrix([[tp, fp],[fn, tn]])\n",
        "  return matrix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q17sdl3qSn4D",
        "outputId": "db631b88-60fb-4cdd-9c57-ded687755ff7"
      },
      "source": [
        "\n",
        "confusionMatrix = ConfusionMatrix(df_a.y, df_a.y_pred)\n",
        "print(f'Confusion Matrix : \\n{confusionMatrix}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            "[[10000   100]\n",
            " [    0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV47GZ31Vu9t"
      },
      "source": [
        "### 2. Compute F1 Score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkSiRvhwWRjb"
      },
      "source": [
        "def ComputeF1Score(confusionMatrix):\n",
        "  tp = confusionMatrix.item((0,0))\n",
        "  tn = confusionMatrix.item((1,1))\n",
        "  fp = confusionMatrix.item((0,1))\n",
        "  fn = confusionMatrix.item((1,0))\n",
        "\n",
        "  precision_score = tp/(tp+fp)\n",
        "  recall_score = tp/(tp+fn)\n",
        "  f1_score = (2 * precision_score * recall_score) / (precision_score + recall_score)\n",
        "  return f1_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxDmsFYtYf_q",
        "outputId": "5acbe6ea-1f6c-4713-dc29-a83d9de56990"
      },
      "source": [
        "f1_score = ComputeF1Score(confusionMatrix)\n",
        "print(f'F1 Score : {f1_score}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score : 0.9950248756218906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-r9RTqLY_j6"
      },
      "source": [
        "### 3. Compute AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9kHlZuZaUf2"
      },
      "source": [
        "  \n",
        "def ComputeAUCscore(y, prob):\n",
        "\n",
        "    thresholds = list(set(prob))\n",
        "    thresholds = sorted(thresholds, reverse=True)\n",
        "\n",
        "    tpr_list, fpr_list = [], []\n",
        "    # thresh_list = {}\n",
        "    for threshold in thresholds :\n",
        "      tpr, fpr = calculate_thresh_tpr_fpr(y, prob, threshold)\n",
        "      tpr_list.append(tpr)\n",
        "      fpr_list.append(fpr)\n",
        "\n",
        "      # thresh_list[threshold] = (tpr, fpr)\n",
        "\n",
        "    auc_score = np.trapz(tpr_list, fpr_list)\n",
        "    return auc_score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZiTzNaOeEja"
      },
      "source": [
        "\n",
        "def calculate_thresh_tpr_fpr(y, proba, threshold):\n",
        "  y_pred_thresh = [0 if prob < threshold else 1 for prob in df_a.proba ]\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for y, y_pred in zip(y, y_pred_thresh):\n",
        "    if y == 0 and y_pred == 0:\n",
        "      tn = tn + 1\n",
        "    elif y == 0 and y_pred == 1:\n",
        "      fp = fp + 1\n",
        "    elif y == 1 and y_pred == 0:\n",
        "      fn = fn + 1\n",
        "    elif y == 1 and y_pred == 1:\n",
        "      tp = tp + 1\n",
        "\n",
        "  tpr = tp / (tp + fn)\n",
        "  fpr = tn / (fp + tn)\n",
        "  return tpr, fpr\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxtfvmbM-26t",
        "outputId": "7542e957-701c-4781-a4a8-1f3480af3da8"
      },
      "source": [
        "auc_score = ComputeAUCscore(df_a.y, df_a.proba)\n",
        "print('AUC Score : ',auc_score)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score :  -0.48829900000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EhPdi4fZatV"
      },
      "source": [
        "### 4. Compute Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8p_dBwOZj5O"
      },
      "source": [
        "def AccuracyScore(confusionMatrix):\n",
        "  tp = confusionMatrix.item((0,0))\n",
        "  fp = confusionMatrix.item((0,1))\n",
        "  fn = confusionMatrix.item((1,0))\n",
        "  tn = confusionMatrix.item((1,1))\n",
        "\n",
        "  acc_score = (tp + tn) / (tp + fp + fn + tn)\n",
        "  return acc_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2gBIXVDaBmm",
        "outputId": "10d7a933-601e-4662-f44c-30ee1cc5c39b"
      },
      "source": [
        "acc_score = ComputeF1Score(confusionMatrix)\n",
        "print(f'Accuracy Score : {acc_score}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score : 0.9950248756218906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KZem1BQvn2"
      },
      "source": [
        "\n",
        "\n",
        "## B. Compute performance metrics for the given data '5_b.csv'\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a>\n",
        "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SZoi_A1qAqbh",
        "outputId": "8cdd7226-ecef-4f5b-9535-1f9aa3002d12"
      },
      "source": [
        "df_b=pd.read_csv('5_b.csv')\n",
        "df_b.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.465152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y     proba\n",
              "0  0.0  0.281035\n",
              "1  0.0  0.465152\n",
              "2  0.0  0.352793\n",
              "3  0.0  0.157818\n",
              "4  0.0  0.276648"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-3sPkZQHKYB"
      },
      "source": [
        "### Deriving class labels from the given score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpjsH22NHKYB",
        "outputId": "ac131f19-87f8-4290-a281-98f22960d2ea"
      },
      "source": [
        "\n",
        "df_b['y_pred'] = [0 if prob < 0.5 else 1 for prob in df_b.proba ]\n",
        "print(df_b.head(10))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     y     proba  y_pred\n",
            "0  0.0  0.281035       0\n",
            "1  0.0  0.465152       0\n",
            "2  0.0  0.352793       0\n",
            "3  0.0  0.157818       0\n",
            "4  0.0  0.276648       0\n",
            "5  0.0  0.190260       0\n",
            "6  0.0  0.320328       0\n",
            "7  0.0  0.435013       0\n",
            "8  0.0  0.284849       0\n",
            "9  0.0  0.427919       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlCe6dDCHKYC"
      },
      "source": [
        "### 1. Computing Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY2Yyyh6HKYC",
        "outputId": "675e5ee5-6b13-4ef9-c131-ee47ea0d1ed0"
      },
      "source": [
        "confusionMatrix = ConfusionMatrix(df_b.y, df_b.y_pred)\n",
        "print(f'Confusion Matrix : \\n{confusionMatrix}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            "[[  55  239]\n",
            " [  45 9761]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAD4FNLhHKYC"
      },
      "source": [
        "### 2. Compute F1 Score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAQ_Ge-5HKYC",
        "outputId": "9bf789f8-ed91-4fe7-d1bf-acf9bfc1ca4e"
      },
      "source": [
        "f1_score = ComputeF1Score(confusionMatrix)\n",
        "print(f'F1 Score : {f1_score}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score : 0.2791878172588833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE6eTHqOHKYD"
      },
      "source": [
        "### 3. Compute AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0l3YsypHKYD",
        "outputId": "395e8f40-3c77-4345-81b1-ef5b1dca173f"
      },
      "source": [
        "auc_score = ComputeAUCscore(df_b.y, df_b.proba)\n",
        "print('AUC Score : ',auc_score)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score :  -0.207154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na8fy2G6HKYD"
      },
      "source": [
        "### 4. Compute Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1E6GSgMHKYD"
      },
      "source": [
        "acc_score = ComputeF1Score(confusionMatrix)\n",
        "print(f'Accuracy Score : {acc_score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sKlq0YQvn5"
      },
      "source": [
        "df_b=pd.read_csv('5_b.csv')\n",
        "df_b.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlLVa-cVAfCS"
      },
      "source": [
        "# write your code here for task B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ne6rQ8gEtTU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiPGonTzQvoB"
      },
      "source": [
        "## C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data \n",
        "<br>\n",
        "\n",
        "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
        "\n",
        "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{number of false positive}$\n",
        "\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HIJzq1QvoE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aa7334a0-c496-44d9-9a54-9b38bdd3c3a0"
      },
      "source": [
        "df_c=pd.read_csv('5_c.csv')\n",
        "df_c.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.458521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.505037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.418652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.412057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.375579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   y      prob\n",
              "0  0  0.458521\n",
              "1  0  0.505037\n",
              "2  0  0.418652\n",
              "3  0  0.412057\n",
              "4  0  0.375579"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAPjewjzAfCa"
      },
      "source": [
        " # write your code for task C"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5AlGM1yBBxK"
      },
      "source": [
        "### Finding Best threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Ib_ODaBZbw"
      },
      "source": [
        " \n",
        " \n",
        "def BestThreshold(y, scores):\n",
        "  thresholds = list(set(scores))\n",
        "  thresholds = sorted(thresholds, reverse=True)\n",
        "  minA = 9876543210\n",
        "  threshMetric = {}\n",
        "\n",
        "  for threshold in thresholds:\n",
        "    y_pred = [0 if prob < threshold else 1 for prob in scores]\n",
        "    confusionMatrix = ConfusionMatrix(y, y_pred)\n",
        "    fn = confusionMatrix.item((1,0))\n",
        "    fp = confusionMatrix.item((0,1))\n",
        "\n",
        "    if fn < fp :\n",
        "      A = CalculateMetric(fn, fp)\n",
        "      if A < minA:\n",
        "        minA = A\n",
        "        bestFN, bestFP = fn, fp\n",
        "      threshMetric[A] = threshold\n",
        "\n",
        "  threshMetric = dict(sorted(threshMetric.items(), key=lambda x:x[1]))\n",
        "\n",
        "  bestThreshold = threshMetric[minA]\n",
        "  return bestThreshold, minA, bestFN, bestFP"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U8QbbvpBxSo"
      },
      "source": [
        "def CalculateMetric(FN, FP):\n",
        "  return (500 * FN) + (100 * FP)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiae6MNuGGFa",
        "outputId": "32754001-28f8-41d2-8f82-dcbbd9e3a052"
      },
      "source": [
        "bestThreshold, metric, bestFN, bestFP = BestThreshold(df_c.y, df_c.prob)\n",
        "print(f'Best Threshold : {bestThreshold} with metric A : {metric} having FN={bestFN} and FP={bestFP}')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold : 0.2300390278970873 with metric A : 141000 having FN=78 and FP=1020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD4CcgjXQvoL"
      },
      "source": [
        "\n",
        "## D.</b></font> Compute performance metrics(for regression) for the given data 5_d.csv\n",
        "<pre>    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
        "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
        "<ol>\n",
        "<li> Compute Mean Square Error </li>\n",
        "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
        "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVOj-bF9AfCd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "166108ff-d63d-4dfc-cd78-f29ee4bb89a4"
      },
      "source": [
        "df_d=pd.read_csv('5_d.csv')\n",
        "df_d.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131.0</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>164.0</td>\n",
              "      <td>125.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154.0</td>\n",
              "      <td>152.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       y   pred\n",
              "0  101.0  100.0\n",
              "1  120.0  100.0\n",
              "2  131.0  113.0\n",
              "3  164.0  125.0\n",
              "4  154.0  152.0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRhL1pheAfCe"
      },
      "source": [
        " # write your code for task 5d"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfg4BE_FReXV"
      },
      "source": [
        "### 1. Compute Mean Square Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIOMVXH5SfjR",
        "outputId": "4fbf3704-a814-45cb-9ea8-325e7ce1993e"
      },
      "source": [
        "df_d.info()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 157200 entries, 0 to 157199\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   y       157200 non-null  float64\n",
            " 1   pred    157200 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 2.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBW03JmVRd-p"
      },
      "source": [
        "def Compute_MeanSquareError(actual, predicted):\n",
        "  return np.mean((actual - predicted)**2)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fro6LVY7UR7r",
        "outputId": "e8fa776e-cbdc-4887-b17a-80e8ec46d447"
      },
      "source": [
        "mse = Compute_MeanSquareError(df_d.y, df_d.pred)\n",
        "print(f'Mean Squared Error : {mse:.6f}')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error : 177.165700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkrSMTW0Wk_6"
      },
      "source": [
        "### 2. Compute Mean Absolute Percentage Error(MAPE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHxskc2UWuYo"
      },
      "source": [
        "def Compute_MAPE(actual, predicted):\n",
        "  return (np.mean(np.abs(actual - predicted) / actual ))*100"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Z_oxhXXiqT",
        "outputId": "84c6d11b-b9e9-4b9c-8204-de0556a6c399"
      },
      "source": [
        "mape = Compute_MAPE(df_d.y, df_d.pred)\n",
        "print(f'Mean Absolute Percentage Error : {mape :.2f} %')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error : inf %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDhK2BwEX2Pd"
      },
      "source": [
        "*Our Compute_MAPE() output is not defined. It can be due to zeros present in out actual values.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFU0bUn8W35q",
        "outputId": "2f24541d-b0e9-4534-e797-c524bc6fa4d0"
      },
      "source": [
        "(df_d == 0).any()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y       True\n",
              "pred    True\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAhiqA6JY30h",
        "outputId": "c3324b66-9d6a-420c-8013-4e336f24549f"
      },
      "source": [
        "(df_d < 0).any()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y       False\n",
              "pred     True\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ-adGGqYMgH"
      },
      "source": [
        "*As we see zeroes are present in actual values. Also all actual values are positive. So our Compute_MAPE() function needs to be modified as follows :-*\n",
        "<br>\n",
        "error = actual value - predicted value <br>\n",
        "Let **mean_a** = average of **N** actual values<br>\n",
        "or  **N** * **mean_a** = sum of **N** actual values = sum of **N** |actual values|<br>\n",
        "\n",
        "modified_MAPE = 1/**N** * sum of all **|error|**/mean_a <br>\n",
        "              = sum of all **|error|** / sum of all actual values<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbhunkTWbLBQ"
      },
      "source": [
        "def Compute_MAPEmodified(actual, predicted):\n",
        "  return (sum(np.abs(actual - predicted)) / sum(actual))*100"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AB84MTNbuSq",
        "outputId": "5dc803af-fb19-4af0-c00d-93be527c3398"
      },
      "source": [
        "mape = Compute_MAPEmodified(df_d.y, df_d.pred)\n",
        "print(f'Mean Absolute Percentage Error : {mape :.2f}%')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error : 12.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnNRhsf1cq3o"
      },
      "source": [
        "### 3. Compute R^2 error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhvMW0OVdCao"
      },
      "source": [
        "def Compute_R2Error(actual, predicted):\n",
        "  SSres = sum( (actual - predicted)**2)\n",
        "  mean_y = np.mean(actual)\n",
        "  SStot = sum((actual - mean_y)**2)\n",
        "  return 1 - (SSres / SStot)\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhyugLkbeGTf",
        "outputId": "cf8603ab-76c5-4c0e-e040-896c648db2b8"
      },
      "source": [
        "r2 = Compute_R2Error(df_d.y, df_d.pred)\n",
        "print(f'R-Squared Error : {r2:.6f}')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-Squared Error : 0.956358\n"
          ]
        }
      ]
    }
  ]
}